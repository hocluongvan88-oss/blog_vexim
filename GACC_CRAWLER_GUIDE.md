# GACC News Crawler - HÆ°á»›ng Dáº«n Sá»­ Dá»¥ng

## ğŸ¯ Tá»•ng Quan

Há»‡ thá»‘ng crawl tin tá»©c GACC Ä‘Æ°á»£c thiáº¿t káº¿ theo **best practices** Ä‘á»ƒ:
- âœ… KhÃ´ng vi pháº¡m website gá»‘c
- âœ… Nháº¹, an toÃ n, khÃ´ng bá»‹ cháº·n
- âœ… Chá»‰ láº¥y dá»¯ liá»‡u khi cÃ³ thay Ä‘á»•i
- âœ… TÃ­ch há»£p AI phÃ¢n tÃ­ch thÃ´ng minh

## ğŸ”§ Cáº¥u HÃ¬nh

### 2 URL GACC ÄÆ°á»£c Crawl

\`\`\`
1. http://www.customs.gov.cn/customs/302249/302266/index.html
2. http://www.customs.gov.cn/customs/302249/2480148/index.html
\`\`\`

**LÆ°u Ã½:** Há»‡ thá»‘ng KHÃ”NG crawl toÃ n site, chá»‰ 2 trang nÃ y Ä‘á»ƒ Ä‘áº£m báº£o an toÃ n.

## ğŸ“‹ Workflow "WATCH PAGE + HASH"

### BÆ°á»›c 1: Láº¥y Danh SÃ¡ch (List Only)

\`\`\`
âŒ KHÃ”NG: Fetch toÃ n bá»™ ná»™i dung ngay
âœ… NÃŠN: Chá»‰ láº¥y danh sÃ¡ch link
\`\`\`

ThÃ´ng tin láº¥y:
- TiÃªu Ä‘á» (title)
- URL bÃ i viáº¿t
- NgÃ y ban hÃ nh
- MÃ£ vÄƒn báº£n (náº¿u cÃ³)

### BÆ°á»›c 2: Hash Detection

\`\`\`typescript
// Táº¡o hash tá»« title + date + url
hash = sha256(title + date + url)
\`\`\`

**Logic:**
- Hash thay Ä‘á»•i = cÃ³ bÃ i viáº¿t má»›i hoáº·c cáº­p nháº­t
- Hash khÃ´ng Ä‘á»•i = bá» qua (Ä‘Ã£ crawl rá»“i)

### BÆ°á»›c 3: Fetch Content CÃ³ Äiá»u Kiá»‡n

\`\`\`
IF hash má»›i hoáº·c thay Ä‘á»•i:
  â†’ Fetch ná»™i dung chi tiáº¿t
  â†’ PhÃ¢n tÃ­ch vá»›i AI
  â†’ LÆ°u vÃ o database
ELSE:
  â†’ Bá» qua (tiáº¿t kiá»‡m tÃ i nguyÃªn)
\`\`\`

## ğŸ¤– AI Processing - ÄÃºng Chá»—

### AI KHÃ”NG Ä‘á»c toÃ n bá»™. AI chá»‰ nháº­n:

1. **TiÃªu Ä‘á»** - Ä‘á»ƒ hiá»ƒu chá»§ Ä‘á» chÃ­nh
2. **Pháº§n thay Ä‘á»•i** - chá»‰ ná»™i dung má»›i
3. **Metadata** - ngÃ y, nguá»“n, danh má»¥c

### Prompt Máº«u (TÆ° Duy ÄÃºng)

\`\`\`
VÄƒn báº£n nÃ y cÃ³ pháº£i lÃ :
- Thay Ä‘á»•i nghÄ©a vá»¥ DN?
- Hay chá»‰ diá»…n giáº£i?

Ãp dá»¥ng cho:
- DN sáº£n xuáº¥t?
- DN thÆ°Æ¡ng máº¡i?

Sáº£n pháº©m áº£nh hÆ°á»Ÿng:
- Thá»±c pháº©m
- Háº£i sáº£n
- NÃ´ng sáº£n
\`\`\`

## ğŸ¯ Map Vá»›i Profile User (ChÃ¬a KhÃ³a Giá»¯ ChÃ¢n)

### VÃ­ dá»¥ User Profile:

\`\`\`json
{
  "product": "thá»±c pháº©m",
  "market": "Trung Quá»‘c",
  "role": "thÆ°Æ¡ng máº¡i"
}
\`\`\`

### AI Káº¿t Luáº­n:

\`\`\`
âœ… "VÄƒn báº£n nÃ y cÃ³ kháº£ nÄƒng áº£nh hÆ°á»Ÿng vÃ¬ cÃ³ Ä‘á» cáº­p Ä‘áº¿n DN khÃ´ng cÃ³ nhÃ  mÃ¡y"
   â†’ Gá»­i notify

âŒ "VÄƒn báº£n nÃ y chá»‰ Ä‘á» cáº­p Ä‘áº¿n dÆ°á»£c pháº©m"
   â†’ KHÃ”NG gá»­i (trÃ¡nh spam)
\`\`\`

**Káº¿t quáº£:** User khÃ´ng bá»‹ spam â†’ tin tÆ°á»Ÿng há»‡ thá»‘ng.

## ğŸ“§ ThÃ´ng BÃ¡o NÃªn Viáº¿t Tháº¿ NÃ o?

### âŒ Sai:
\`\`\`
"CÃ³ vÄƒn báº£n má»›i cá»§a GACC"
\`\`\`

### âœ… ÄÃºng:
\`\`\`
"GACC cáº­p nháº­t quy Ä‘á»‹nh há»“ sÆ¡ Ä‘á»‘i vá»›i DN thÆ°Æ¡ng máº¡i xuáº¥t thá»±c pháº©m (ban hÃ nh 21/01/2026)"
\`\`\`

## ğŸš€ MVP Thá»±c Táº¿ Cho VEXIM

### 30 NgÃ y Äáº§u

**Theo dÃµi:**
- æ”¿åŠ¡å…¬å¼€ â†’ æœ€æ–°æ–‡ä»¶
- æµ·å…³æ³•è§„

**Chá»‰ cho:**
- Thá»±c pháº©m
- DN thÆ°Æ¡ng máº¡i

ğŸ‘‰ **ÄÃ£ vÆ°á»£t 90% website Ä‘á»‘i thá»§**

## ğŸ” Security & Anti-Block

### Secure Headers (Implemented)

\`\`\`typescript
{
  "User-Agent": "Mozilla/5.0 Chrome/120.0.0.0",
  "Accept-Language": "zh-CN,zh;q=0.9",
  "Referer": "http://www.customs.gov.cn/",
  "Sec-CH-UA": '"Chromium";v="120"'
}
\`\`\`

### Cookie Management

\`\`\`
1. Láº¥y cookie tá»« homepage trÆ°á»›c
2. Sá»­ dá»¥ng cookie cho crawl requests
3. Handle 412 errors gracefully
\`\`\`

## ğŸ“Š Database Schema

### Table: `crawled_news`

\`\`\`sql
id              UUID
source          TEXT         -- 'FDA' hoáº·c 'GACC'
source_url      TEXT         -- URL trang Ä‘Æ°á»£c crawl
title           TEXT
article_url     TEXT UNIQUE  -- URL bÃ i viáº¿t
published_date  TEXT
content_hash    TEXT         -- SHA256 hash (key field!)
full_content    TEXT         -- Ná»™i dung Ä‘áº§y Ä‘á»§
summary         TEXT
relevance       TEXT         -- 'high', 'medium', 'low'
categories      TEXT[]
ai_analysis     JSONB        -- Káº¿t quáº£ AI
status          TEXT         -- 'pending', 'processed', 'published'
is_notified     BOOLEAN
created_at      TIMESTAMPTZ
updated_at      TIMESTAMPTZ
last_checked_at TIMESTAMPTZ
\`\`\`

### Table: `crawl_sessions`

\`\`\`sql
id              UUID
source          TEXT
source_url      TEXT
started_at      TIMESTAMPTZ
completed_at    TIMESTAMPTZ
status          TEXT         -- 'running', 'completed', 'failed'
articles_found  INTEGER
new_articles    INTEGER      -- Sá»‘ bÃ i má»›i (hash khÃ¡c)
updated_articles INTEGER     -- Sá»‘ bÃ i cáº­p nháº­t
error_message   TEXT
metadata        JSONB
\`\`\`

## ğŸ’¡ Best Practices

### DO âœ…

1. **Watch specific pages** - Chá»‰ crawl 2 URL Ä‘Ã£ Ä‘á»‹nh
2. **Hash-based detection** - Detect thay Ä‘á»•i báº±ng hash
3. **Lazy content loading** - Chá»‰ fetch khi cáº§n
4. **AI on changes only** - AI chá»‰ xá»­ lÃ½ pháº§n má»›i
5. **User profile matching** - Gá»­i notify cÃ³ target
6. **Meaningful notifications** - ThÃ´ng bÃ¡o chi tiáº¿t, cÃ³ giÃ¡ trá»‹

### DON'T âŒ

1. ~~Crawl toÃ n site~~
2. ~~Crawl trang cÃ³ tÆ°Æ¡ng tÃ¡c~~
3. ~~Crawl vá»›i táº§n suáº¥t cao~~
4. ~~Fetch content cho má»i item~~
5. ~~Gá»­i notify spam~~
6. ~~AI phÃ¢n tÃ­ch toÃ n bá»™~~

## ğŸ“ˆ Performance Metrics

### Target Goals

- **Crawl time**: < 30s per session
- **Hash comparison**: < 1s per 100 items
- **Content fetch**: Only on changes (5-10% of items)
- **AI processing**: Only relevant articles (10-20% after filtering)
- **False positive**: < 5%
- **User satisfaction**: > 90% (notifications are useful)

## ğŸ”„ Workflow Flow Chart

\`\`\`
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. CRAWL DANH SÃCH (List Only)             â”‚
â”‚    - Title, URL, Date                       â”‚
â”‚    - NO content fetching yet                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. GENERATE HASH                            â”‚
â”‚    hash = sha256(title + date + url)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. CHECK HASH IN DATABASE                   â”‚
â”‚    - Existing hash? â†’ Skip                  â”‚
â”‚    - New/changed hash? â†’ Continue           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼ (Only if new/changed)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. FETCH FULL CONTENT                       â”‚
â”‚    - Download article page                  â”‚
â”‚    - Strip menu, sidebar                    â”‚
â”‚    - Extract main content                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. AI ANALYSIS (3 Tiers)                    â”‚
â”‚    Tier 1: Keyword filter                   â”‚
â”‚    Tier 2: Relevance scoring                â”‚
â”‚    Tier 3: Detailed validation              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 6. MAP WITH USER PROFILE                    â”‚
â”‚    - Match product/market/role              â”‚
â”‚    - Calculate impact                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 7. SEND TARGETED NOTIFICATION               â”‚
â”‚    - Only to affected users                 â”‚
â”‚    - Meaningful message                     â”‚
â”‚    - Include action items                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\`\`\`

## ğŸ› ï¸ Code Examples

### Example 1: Crawl & Hash

\`\`\`typescript
// Crawl danh sÃ¡ch
const articles = await crawler.crawlGACCNews()

// articles[0]:
{
  "title": "å…³äºè¿›å£é£Ÿå“ä¼ä¸šæ³¨å†Œçš„å…¬å‘Š",
  "url": "http://www.customs.gov.cn/customs/.../xxx.html",
  "date": "2026-01-21",
  "contentHash": "a3f5b8c...",  // SHA256 hash
  "source": "GACC",
  "sourceUrl": "http://www.customs.gov.cn/customs/302249/302266/index.html"
}
\`\`\`

### Example 2: Check & Fetch

\`\`\`typescript
// Check hash trong DB
const existing = await db.findByHash(article.contentHash)

if (!existing) {
  // Hash má»›i â†’ fetch content
  const fullContent = await crawler.fetchArticleContent(
    article.url, 
    article.source
  )
  
  // Analyze vá»›i AI
  const analysis = await crawler.processNewsArticle(JSON.stringify({
    ...article,
    fullContent
  }))
  
  // Save to DB
  await db.save({
    ...article,
    fullContent,
    ai_analysis: analysis
  })
}
\`\`\`

### Example 3: User Matching

\`\`\`typescript
// Láº¥y users liÃªn quan
const affectedUsers = await db.query(`
  SELECT * FROM user_profiles 
  WHERE product = ANY($1)
  AND market = ANY($2)
`, [analysis.affectedProducts, analysis.affectedCountries])

// Gá»­i notify cÃ³ target
for (const user of affectedUsers) {
  await sendNotification(user, {
    title: `${article.source} cáº­p nháº­t: ${article.title}`,
    body: analysis.summary,
    actionUrl: article.url
  })
}
\`\`\`

## ğŸ“ Support

Náº¿u cÃ³ váº¥n Ä‘á», kiá»ƒm tra:

1. **Console logs** - Xem `[v0]` prefix logs
2. **Database** - Check `crawl_sessions` table
3. **Headers** - Verify secure headers Ä‘Æ°á»£c gá»­i
4. **Hash** - Kiá»ƒm tra hash generation
5. **AI API** - Xem Groq API credits

## ğŸ“ TÃ³m Táº¯t

Há»‡ thá»‘ng nÃ y Ä‘Æ°á»£c xÃ¢y dá»±ng theo **best practices**:

âœ… **Lightweight** - Chá»‰ fetch khi cáº§n
âœ… **Safe** - KhÃ´ng vi pháº¡m robots.txt
âœ… **Smart** - AI phÃ¢n tÃ­ch cÃ³ target
âœ… **Effective** - User chá»‰ nháº­n notify quan trá»ng
âœ… **Scalable** - Dá»… má»Ÿ rá»™ng thÃªm sources

ğŸ‘‰ **Káº¿t quáº£:** Má»™t há»‡ thá»‘ng crawl tin tá»©c xuáº¥t nháº­p kháº©u Tá»T NHáº¤T thá»‹ trÆ°á»ng!
